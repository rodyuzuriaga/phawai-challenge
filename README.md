# PhawAI: PredicciÃ³n de Enfermedades Coronarias

[![Kaggle Competition](https://img.shields.io/badge/Kaggle-Competition-blue)](https://www.kaggle.com/competitions/prediccion-de-sufrir-enfermedades-coronarias)

Este repositorio contiene los archivos, cÃ³digos y documentaciÃ³n del proyecto **PhawAI**, enfocado en desarrollar un modelo de Machine Learning para predecir enfermedades coronarias usando el dataset proporcionado por el Behavioral Risk Factor Surveillance System (BRFSS) 2022. 

---

## ðŸ“œ Tabla de Contenidos
- [IntroducciÃ³n](#introducciÃ³n)
- [Objetivos del Proyecto](#objetivos-del-proyecto)
- [Estructura del Repositorio](#estructura-del-repositorio)
- [Requisitos Previos](#requisitos-previos)
- [Instrucciones de Uso](#instrucciones-de-uso)
- [MÃ©tricas de EvaluaciÃ³n](#mÃ©tricas-de-evaluaciÃ³n)
- [Enfoque del Proyecto](#enfoque-del-proyecto)
- [VisualizaciÃ³n de Resultados](#visualizaciÃ³n-de-resultados)
- [Referencias](#referencias)

---

## ðŸ“– IntroducciÃ³n

Las enfermedades coronarias son una de las principales causas de muerte a nivel mundial. Este proyecto tiene como objetivo aprovechar el dataset **BRFSS 2022**, que incluye informaciÃ³n demogrÃ¡fica, hÃ¡bitos de salud y condiciones previas, para construir modelos predictivos que puedan identificar individuos con riesgo de padecer enfermedades coronarias. 

### DesafÃ­os del Proyecto:
- Dataset desbalanceado con pocos casos positivos.
- Manejo de valores nulos y caracterÃ­sticas no relevantes.
- Uso de mÃ©tricas como F1-score para evaluaciÃ³n en lugar de precisiÃ³n estÃ¡ndar.

---

## ðŸŽ¯ Objetivos del Proyecto

1. **PredicciÃ³n precisa**: Desarrollar un modelo de Machine Learning para predecir enfermedades coronarias usando variables relevantes.
2. **Balanceo de datos**: Implementar tÃ©cnicas como sobremuestreo o submuestreo para mitigar el desbalance de clases.
3. **OptimizaciÃ³n**: Usar tÃ©cnicas avanzadas de preprocesamiento, selecciÃ³n de caracterÃ­sticas y ajuste de hiperparÃ¡metros para maximizar el F1-score.
4. **Escalabilidad**: Crear un pipeline reproducible y eficiente para su potencial uso en implementaciones reales.

---

## ðŸ“‚ Estructura del Repositorio

```plaintext
PhawAI/
â”‚
â”œâ”€â”€ data/                    # Archivos de datos
â”‚   â”œâ”€â”€ train.csv            # Dataset de entrenamiento
â”‚   â”œâ”€â”€ test_public.csv      # Dataset de prueba pÃºblica
â”‚   â””â”€â”€ test_private.csv     # Dataset de prueba privada
â”‚
â”œâ”€â”€ notebooks/               # Notebooks de Jupyter
â”‚   â””â”€â”€ phawai-challenge-rody-uzuriaga.ipynb
â”‚       â”œâ”€â”€ 1. PreparaciÃ³n del Notebook
â”‚       â”œâ”€â”€ 2. AnÃ¡lisis Exploratorio de Datos (EDA)
â”‚       â”œâ”€â”€ 3. Preprocesamiento
â”‚       â”œâ”€â”€ 4. Balanceo de Clases
â”‚       â”œâ”€â”€ 5. Entrenamiento del Modelo
â”‚       â”œâ”€â”€ 6. Ensamblaje de Modelos
â”‚       â”œâ”€â”€ 7. GeneraciÃ³n de Predicciones
â”‚       â””â”€â”€ 8. VisualizaciÃ³n de Resultados
â”‚
â”œâ”€â”€ results/                 # Resultados y archivos de salida
â”‚   â””â”€â”€ resultados.csv       # Archivo de predicciones para Kaggle
â”‚
â”œâ”€â”€ README.md                # Este archivo
â””â”€â”€ requirements.txt         # Dependencias del proyecto
```

---

## ðŸ’» Requisitos Previos

Antes de comenzar, asegÃºrate de tener instalados los siguientes programas:
- **Python** (versiÃ³n 3.8 o superior)
- **Jupyter Notebook**
- Bibliotecas listadas en `requirements.txt`

Instala las dependencias usando:
```bash
pip install -r requirements.txt
```

---

## ðŸ›  Instrucciones de Uso

1. Clona el repositorio:
   ```bash
   git clone https://github.com/rodyuzuriaga/phawai-challenge.git
   cd phawai-challenge
   ```

2. Abre el notebook principal:
   ```bash
   jupyter notebook notebooks/phawai-challenge-rody-uzuriaga.ipynb
   ```

3. Sigue los pasos del notebook, que incluyen:
   - **ExploraciÃ³n de datos**
   - **Preprocesamiento**
   - **Entrenamiento de modelos**
   - **GeneraciÃ³n de predicciones**

4. Genera el archivo `resultados.csv` en la carpeta `results/`.

5. Sube el archivo generado a Kaggle para la evaluaciÃ³n final.

---

## ðŸ“Š MÃ©tricas de EvaluaciÃ³n

El desempeÃ±o del modelo se evalÃºa usando el **F1-score**, ideal para datasets desbalanceados como este. TambiÃ©n se utilizan las siguientes mÃ©tricas:
- **ROC-AUC:** Mide la capacidad del modelo para diferenciar entre clases.
- **Matriz de confusiÃ³n:** Proporciona una vista detallada de verdaderos positivos, negativos y errores.

---

## ðŸ“ˆ VisualizaciÃ³n de Resultados

1. **Matriz de ConfusiÃ³n**:
   - Representa la clasificaciÃ³n correcta y errÃ³nea de las predicciones.
     
     ![image](https://github.com/user-attachments/assets/28b05be6-dd71-41e1-a8f8-4f4bde88548d)

   
2. **Curva Precision-Recall**:
   - EvalÃºa la relaciÃ³n entre precisiÃ³n y recall en diferentes umbrales.
  
     ![image](https://github.com/user-attachments/assets/437d7f44-f625-486d-9dce-7bf4ca7b7fe5)


3. **Curva ROC y AUC**:
   - Muestra la capacidad del modelo para diferenciar entre clases.
  
     ![image](https://github.com/user-attachments/assets/65a8ba5f-42a6-4379-b9a2-4ff78370ae8a)


4. **Heatmap del F1 Score por Clase**:
   - Indica un buen equilibrio entre precisiÃ³n y recall, con un alto F1-score para ambas clases.
  
     ![image](https://github.com/user-attachments/assets/746897ec-2833-473c-918c-0b9d510db0eb)


4. **Importancia de CaracterÃ­sticas**:
   - Identifica las variables mÃ¡s relevantes para la predicciÃ³n.
  
     ![image](https://github.com/user-attachments/assets/7087b289-0488-45a7-9f92-21b9c4cf2393)
     

---

## ðŸ“š Referencias

1. [Dataset BRFSS 2022](https://www.cdc.gov/brfss/annual_data/annual_2022.html)
2. [Kaggle Competition](https://www.kaggle.com/competitions/prediccion-de-sufrir-enfermedades-coronarias)
3. Breiman, L. (2001). Random Forests. *Machine Learning, 45(1), 5-32*.
4. Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. *Proceedings of the 22nd ACM SIGKDD*.

---

### **requirements.txt**
```
pandas
numpy
matplotlib
seaborn
scikit-learn
imbalanced-learn
xgboost
lightgbm
```
---

### Tabla de Contenidos del Notebook
```
1. PreparaciÃ³n del Notebook  
2. AnÃ¡lisis Exploratorio de Datos (EDA)  
3. Preprocesamiento  
4. Balanceo de Clases  
5. Entrenamiento del Modelo  
6. Ensamblaje de Modelos  
7. GeneraciÃ³n de Predicciones  
8. VisualizaciÃ³n de Resultados
```
